<DOC>
<DOCNO>SK-technology-1158-20180721</DOCNO>
<URL>https://www.skynewsarabia.com/technology/1166112-%D9%83%D8%A8%D8%A7%D8%B1-%D8%A7%D9%84%D8%AA%D9%82%D9%86%D9%8A%D8%A9-%D9%8A%D8%AD%D8%B0%D8%B1%D9%88%D9%86-%D8%A7%D9%84%D8%B1%D9%88%D8%A8%D9%88%D8%AA-%D8%A7%D9%84%D9%82%D8%A7%D8%AA%D9%84</URL>
<SRC>skynews</SRC>
<CAT>technology</CAT>
<TITLE>كبار التقنية يحذرون من "الروبوت القاتل"</TITLE>
<TIME>Sat, 21 Jul 2018 10:35:09 GMT</TIME>
<AUTHOR>أبوظبي - سكاي نيوز عربية</AUTHOR>
<ABSTRACT>
دعا خبراء رقميون ومستثمرون في الذكاء الاصطناعي، حكومات العالم إلى التحرك بشكل مسبق، للحؤول دون تطوير الروبوتات القاتلة، منبهين إلى ما تنذر به من فظاعات في المستقبل إذا لم يجر منعها.
</ABSTRACT>
<TEXT>
دعا خبراء رقميون ومستثمرون في الذكاء الاصطناعي، حكومات العالم إلى التحرك بشكل مسبق، للحؤول دون تطوير الروبوتات القاتلة، منبهين إلى ما تنذر به من فظاعات في المستقبل إذا لم يجر منعها.
وذكرت صحيفة "واشنطن بوست"، أن فاعلين كبارا في مجال التقنية مثل مؤسس شركة الفضاء الأميركية إلون موسك، دعوا إلى الانتباه لمخاطر الإنسان الآلي القاتل، قبل فوات الأوان.
ويقول الرافضون لتطوير "الروبوتات القاتلة" إن الأسلحة "الذكية" ستفاقم حصيلة الضحايا في الحروب، كما أن المحاكم والقوانين الدولية قد تجد صعوبة في تحديد الجناة، على اعتبار أن المرتكب المحتمل سيكون آليا.
وفضلا عن ذلك، يملك العسكري العادي سلطة تقديرية فيتخذ قراراه - من حيث المبدأ - بعد التمحيص والتأكد من عدم وجود المدنيين أو أشخاص صغار، وهو أمر يصعب أن يقوم به الإنسان الآلي.
وقدم رواد التقنية هذا الأسبوع لائحة وقعها أكثر من 2460 شخصا من مجال التقنية و160 مؤسسة، الغرض منها التراجع عن توظيف الذكاء الاصطناعي في مجال التسلح.
وضمت قائمة الموقعين جان تالين، أحد مؤسسي تطبيق واتساب، فضلا عن الخبير البارز في مجال الذكاء الصناعي ستوارت راسل.
ودعا الموقعون الحكومات إلى تشريع قوانين تؤطر استخدام الذكاء الصناعي في مجال الأسلحة، لاسيما أن إقبال أي طرف على التزود بالروبوتات القاتلة سيجشع آخرين على القيام بالأمر نفسه.
</TEXT>
</DOC>
